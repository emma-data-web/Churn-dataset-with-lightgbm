# Churn-dataset-with-lightgbm
Predicting customer churn using LightGBM on the Telco Customer Churn Dataset.

ğŸš€ Project Overview
This project demonstrates:
âœ… End-to-end machine learning workflow on a real-world churn dataset
âœ… Data cleaning and leakage handling
âœ… Feature engineering and categorical handling
âœ… LightGBM model training with GridSearchCV hyperparameter tuning
âœ… Model evaluation with classification report, confusion matrix, ROC-AUC
âœ… SHAP for model interpretability
âœ… Best practices for robust ML pipelines

ğŸ—‚ï¸ Dataset
Telco Customer Churn dataset

~7,000+ samples

Categorical and numerical features including:

Customer demographics

Contract and billing information

Service usage data

Target: Churn Label (Yes/No)

âš™ï¸ Key Libraries
pandas, numpy

scikit-learn

lightgbm

shap

matplotlib, seaborn

ğŸ› ï¸ Project Steps
âœ… 1ï¸âƒ£ Data Cleaning:

Removed leakage columns (Churn Value, CLTV, etc.)

Handled categorical and numerical columns appropriately

Managed missing values in Total Charges

âœ… 2ï¸âƒ£ Feature Engineering:

Split LatLon into Latitude and Longitude

Encoded categorical variables using OneHotEncoder within a pipeline

âœ… 3ï¸âƒ£ Model Building:

Built a LightGBM Classifier within a Pipeline and ColumnTransformer

Used GridSearchCV with 5-fold CV for hyperparameter tuning

âœ… 4ï¸âƒ£ Evaluation:

Accuracy, precision, recall, F1-score

Confusion Matrix

ROC-AUC Score

âœ… 5ï¸âƒ£ Model Interpretation:

Used SHAP to interpret LightGBM feature importances and individual predictions.

ğŸ“Š Results
Achieved ~98% accuracy on the test set.

ROC-AUC Score: ~0.99, indicating strong predictive performance.

Visualized feature importances to understand top churn drivers.

Author -- Nwankwo Emmanuel Ota
